# Subjective-Answer-Script-Evaluation
1.Introduction
â€¢ Revealing the subtleties: A subjective answer script evaluation using
NLP- powered
approach.
The field of educational evaluation is always aiming to find a
equilibrium among effectiveness, precision, and impartiality.
Assessing subjective answer papers poses a distinct difficulty
compared to objective ones. In this case, it is crucial for human
judgment to evaluate the student's response in terms of quality,
clarity, and adherence to the prompt. Nevertheless, these
conventional methods have their drawbacks. Grading manually can
take up a lot of time and money, and may lead to discrepancies
among graders. This report explores the creation of a system
utilizing Natural Language Processing (NLP) to tackle these
deficiencies and introduce a new era of subjective answer script
assessment.
This new system utilizes NLP methods to partially automate the
assessment procedure. The system gives an objective score to
complement human assessment by measuring the semantic
similarity between a student's response and a reference answer or
template. This score serves as a useful instrument for assessors,
providing information on answer content and decreasing the time
needed for manual evaluation. Therefore, the system aims to attain
a triple benefit:
A. Improved Effectiveness: By automating the initial evaluation
using similarity scores, lessening the time pressure on human
assessors, results in quicker feedback for students.
B. Enhanced Objectivity: Semantic similarity scores provide a
more unbiased evaluation of answer quality, reducing discrepancies
caused by varying subjective interpretations by
different graders.
C. Assisted Graders: The system aids human graders by offering
extra data points to assist in their evaluation process.
This report thoroughly examines the issue and its reasons, analyzing
the constraints of conventional grading techniques. It then travels
through the relevant literature, exploring current methods for
automated essay scoring and subjective answer evaluation. Methods
such as feature-based analysis, machine learning algorithms, and
sentence embedding with similarity measures are highlighted,
leading the way for the proposed NLP-based system to be
introduced.
The following sections carefully analyze the design and development
of the system, offering a detailed look at its features. Every step,
including data preprocessing, text cleaning, sentence embedding
model implementation, and user-friendly interface construction, is
thoroughly elaborated on. The report goes on to explore the
evaluation process in detail, including the test cases utilized and the
analysis of human agreement to evaluate the system's efficiency.
The findings and examination reveal what the system can and cannot
do, sparking a thorough conversation that sets the stage for future
progress.
This report ends by outlining the accomplishments of the suggested
NLP system and proposing potential directions for future research.
By accepting the advantages of NLP, the system takes a big stride
towards a more efficient, objective, and ultimately, a more effective
method of evaluating subjective answer
scripts.
